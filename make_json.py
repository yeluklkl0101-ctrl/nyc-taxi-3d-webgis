import pandas as pd
import geopandas as gpd
import json
import os

# ================= é…ç½®åŒº =================
# ç¡®ä¿æ–‡ä»¶åå’Œä½ æˆªå›¾é‡Œçš„ä¸€è‡´
PARQUET_FILE = 'fhvhv_tripdata_2025-07.parquet' 
SHP_FILE = 'taxi_zones/taxi_zones.shp'  # å‡è®¾ä½ çš„shpæ–‡ä»¶åœ¨è¿™ä¸ªå­æ–‡ä»¶å¤¹ï¼Œå¦‚æœä¸æ˜¯è¯·ä¿®æ”¹
OUTPUT_FILE = 'trips_data.json'                 
SAMPLE_SIZE = 20000   # æ—¢ç„¶ä½ æœ‰1900ä¸‡æ¡æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç¨å¾®å¤šå–ä¸€ç‚¹ï¼Œè®¾ä¸º2ä¸‡æ¡ï¼Œæ•ˆæœæ›´å£®è§‚ï¼
# ============================================

def generate_final_json():
    print("--- ğŸš€ å¼€å§‹ç”Ÿæˆæœ€ç»ˆç‰ˆ JSON ---")
    
    # 1. å‡†å¤‡åœ°å›¾æ•°æ®
    print("1. è¯»å–åœ°å›¾åŒºåŸŸæ•°æ®...")
    # è‡ªåŠ¨å¯»æ‰¾ shapefileï¼Œé˜²æ­¢è·¯å¾„é”™è¯¯
    if not os.path.exists(SHP_FILE):
        # å°è¯•å¸¸è§è·¯å¾„
        if os.path.exists(r'D:\è°·æ­Œä¸‹è½½\taxi_zones\taxi_zones.shp'):
             real_shp_path = r'D:\è°·æ­Œä¸‹è½½\taxi_zones\taxi_zones.shp'
        else:
             print(f"âŒ æ‰¾ä¸åˆ° {SHP_FILE}ï¼Œè¯·ä¿®æ”¹ä»£ç ä¸­çš„ SHP_FILE è·¯å¾„")
             return
    else:
        real_shp_path = SHP_FILE

    gdf = gpd.read_file(real_shp_path)
    gdf['LocationID'] = gdf['LocationID'].astype(int)
    gdf = gdf.to_crs(epsg=4326) 
    
    # æ„å»ºåæ ‡å­—å…¸
    zone_dict = {}
    for index, row in gdf.iterrows():
        zone_dict[row['LocationID']] = [row.geometry.centroid.x, row.geometry.centroid.y]
    
    print("   âœ… åœ°å›¾å­—å…¸å‡†å¤‡å®Œæ¯•ã€‚")

    # 2. è¯»å–å‡ºç§Ÿè½¦æ•°æ®
    print("2. è¯»å– Parquet æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
    # æ ¹æ®ä½ çš„æˆªå›¾ï¼Œåˆ—åç¡®è®¤æ˜¯ 'pickup_datetime'
    try:
        df = pd.read_parquet(PARQUET_FILE, columns=['PULocationID', 'DOLocationID', 'pickup_datetime'])
    except Exception as e:
        # å¦‚æœå½“å‰ç›®å½•ä¸‹æ‰¾ä¸åˆ°ï¼Œå°è¯•ç»å¯¹è·¯å¾„ (æ ¹æ®ä½ çš„æˆªå›¾æ¨æµ‹)
        print(f"   âš ï¸ å½“å‰ç›®å½•æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œå°è¯•ç»å¯¹è·¯å¾„...")
        df = pd.read_parquet(r'D:\è°·æ­Œä¸‹è½½\fhvhv_tripdata_2025-07.parquet', columns=['PULocationID', 'DOLocationID', 'pickup_datetime'])

    # 3. æ•°æ®æ¸…æ´—ä¸é‡‡æ ·
    df = df.dropna()
    
    print(f"   ğŸ“Š åŸå§‹æ•°æ®å…± {len(df)} æ¡ï¼Œæ­£åœ¨éšæœºæŠ½å– {SAMPLE_SIZE} æ¡...")
    if len(df) > SAMPLE_SIZE:
        df = df.sample(n=SAMPLE_SIZE)
    
    # 4. æ—¶é—´è½¬æ¢ (å…³é”®æ­¥éª¤ï¼)
    print("3. æ­£åœ¨è®¡ç®—æ—¶é—´ç§’æ•°...")
    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])
    
    # å°†æ—¶é—´è½¬æ¢ä¸º 0-86400 çš„ç§’æ•°
    df['trip_time'] = df['pickup_datetime'].dt.hour * 3600 + \
                      df['pickup_datetime'].dt.minute * 60 + \
                      df['pickup_datetime'].dt.second
    
    # æŒ‰æ—¶é—´æ’åºï¼Œè¿™æ ·ç½‘é¡µåŠ è½½æ—¶ä¼šæ›´é¡ºæ»‘
    df = df.sort_values(by='trip_time')

    # 5. ç”Ÿæˆ JSON ç»“æ„
    print("4. æ­£åœ¨å†™å…¥ JSON...")
    export_data = []
    match_count = 0
    
    for index, row in df.iterrows():
        pu = int(row['PULocationID'])
        do = int(row['DOLocationID'])
        time_sec = int(row['trip_time'])
        
        # åªæœ‰èµ·ç‚¹å’Œç»ˆç‚¹éƒ½åœ¨åœ°å›¾é‡Œï¼Œä¸”ä¸æ˜¯åŸåœ°æ‰“è½¬çš„è®¢å•æ‰ä¿ç•™
        if pu in zone_dict and do in zone_dict and pu != do:
            export_data.append({
                "from": zone_dict[pu],
                "to": zone_dict[do],
                "time": time_sec  # âœ… è¿™é‡Œç¡®ä¿å†™å…¥äº†æ­£ç¡®çš„æ—¶é—´
            })
            match_count += 1

    # 6. ä¿å­˜æ–‡ä»¶
    with open(OUTPUT_FILE, 'w') as f:
        json.dump(export_data, f)
        
    print("-" * 30)
    print(f"ğŸ‰ æˆåŠŸï¼å·²ç”Ÿæˆæ–‡ä»¶: {OUTPUT_FILE}")
    print(f"ğŸ“… åŒ…å«æ•°æ®: {match_count} æ¡")
    print("ğŸ‘‰ ç°åœ¨å»åˆ·æ–°ç½‘é¡µï¼Œæ‹–åŠ¨æ»‘å—ï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°å®Œç¾çš„åŠ¨ç”»äº†ï¼")

if __name__ == "__main__":
    generate_final_json()