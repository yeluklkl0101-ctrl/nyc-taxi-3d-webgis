import pandas as pd
import geopandas as gpd
import json
import os
import numpy as np

# ================= é…ç½®åŒº =================
PARQUET_FILE = 'fhvhv_tripdata_2025-07.parquet' 
SHP_FILE = 'taxi_zones/taxi_zones.shp'
# æ¯å¤©æŠ½å–çš„æ•°é‡ (å¦‚æœè¦æ›´å¯†é›†çš„æ•ˆæœï¼Œå¯ä»¥æ”¹æˆ 8000 æˆ– 10000)
DAILY_SAMPLE = 5000 
# ============================================

def process_daily_data():
    print("--- ğŸš€ å¼€å§‹æŒ‰å¤©åˆ‡åˆ†æ•°æ® ---")
    
    # 1. å‡†å¤‡åœ°å›¾å­—å…¸
    print("1. è¯»å–åœ°å›¾æ•°æ®...")
    if not os.path.exists(SHP_FILE):
        # å°è¯•ç»å¯¹è·¯å¾„å®¹é”™
        real_shp = r'D:\è°·æ­Œä¸‹è½½\taxi_zones\taxi_zones.shp'
    else:
        real_shp = SHP_FILE
        
    gdf = gpd.read_file(real_shp)
    gdf['LocationID'] = gdf['LocationID'].astype(int)
    gdf = gdf.to_crs(epsg=4326) 
    zone_dict = {row['LocationID']: [row.geometry.centroid.x, row.geometry.centroid.y] for i, row in gdf.iterrows()}

    # 2. è¯»å– Parquet
    print("2. è¯»å–å®Œæ•´ Parquet æ–‡ä»¶ (ç¨å®‰å‹¿èº)...")
    try:
        df = pd.read_parquet(PARQUET_FILE, columns=['PULocationID', 'DOLocationID', 'pickup_datetime'])
    except:
        df = pd.read_parquet(r'D:\è°·æ­Œä¸‹è½½\fhvhv_tripdata_2025-07.parquet', columns=['PULocationID', 'DOLocationID', 'pickup_datetime'])

    df = df.dropna()
    
    # 3. æå–æ—¥æœŸå­—ç¬¦ä¸² (ä¾‹å¦‚ '2025-07-01')
    print("3. æ­£åœ¨åˆ†ææ—¥æœŸåˆ†å¸ƒ...")
    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])
    df['date_str'] = df['pickup_datetime'].dt.strftime('%Y-%m-%d')
    
    # è·å–æ•°æ®é‡ŒåŒ…å«çš„æ‰€æœ‰æ—¥æœŸ
    all_days = df['date_str'].unique()
    all_days.sort()
    
    print(f"   ğŸ“… å‘ç°æ•°æ®æ¶µç›–: {len(all_days)} å¤© (ä» {all_days[0]} åˆ° {all_days[-1]})")

    # 4. å¾ªç¯å¤„ç†æ¯ä¸€å¤©
    for day in all_days:
        print(f"   ğŸ‘‰ æ­£åœ¨å¤„ç†: {day} ...", end="")
        
        # ç­›é€‰è¿™ä¸€å¤©çš„æ•°æ®
        day_df = df[df['date_str'] == day].copy()
        
        # æŠ½æ ·
        if len(day_df) > DAILY_SAMPLE:
            day_df = day_df.sample(n=DAILY_SAMPLE)
            
        # è®¡ç®—ç§’æ•°
        day_df['trip_time'] = day_df['pickup_datetime'].dt.hour * 3600 + \
                              day_df['pickup_datetime'].dt.minute * 60 + \
                              day_df['pickup_datetime'].dt.second
        
        # ä¿®å¤æ—¶é—´ä¸º0çš„æƒ…å†µ (é˜²æ­¢å…¨æ˜¯00:00)
        if (day_df['trip_time'] == 0).sum() > len(day_df) * 0.9:
            day_df['trip_time'] = np.random.randint(0, 86400, size=len(day_df))
            
        day_df = day_df.sort_values(by='trip_time')

        # ç”Ÿæˆ JSON
        export_data = []
        for index, row in day_df.iterrows():
            pu = int(row['PULocationID'])
            do = int(row['DOLocationID'])
            if pu in zone_dict and do in zone_dict and pu != do:
                export_data.append({
                    "from": zone_dict[pu],
                    "to": zone_dict[do],
                    "time": int(row['trip_time'])
                })
        
        # æ–‡ä»¶åæ ¼å¼: trips_2025-07-01.json
        filename = f"trips_{day}.json"
        with open(filename, 'w') as f:
            json.dump(export_data, f)
            
        print(f" âœ… å·²ä¿å­˜ ({len(export_data)} æ¡)")

    print("-" * 30)
    print("ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼è¯·ç¡®ä¿æ‰€æœ‰ trips_xxxx-xx-xx.json æ–‡ä»¶éƒ½åœ¨æ–‡ä»¶å¤¹ä¸­ã€‚")

if __name__ == "__main__":
    process_daily_data()